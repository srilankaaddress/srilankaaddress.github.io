<!DOCTYPE html>
<html lang="zh-CN">

<head>
        <link rel="canonical" href="https://srilankaaddress.github.io/html/category/article-1537.htm" />
    <title>深度学习训练过程中的学习率衰减策略及pytorch实现 - Sri Lanka Address</title>
        <meta charset="utf-8">
    <link rel="icon" href="/assets/addons/xcblog/img/srilankaaddress/favicon.ico" type="image/x-icon"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="AerobicsFit template project">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?e8fff5fa52c11c99c5cdad6284174bdb";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
    <link rel="stylesheet" type="text/css" href="/assets/addons/xcblog/css/srilankaaddress/bootstrap-4.1.2/bootstrap.min.css">
    <link href="/assets/addons/xcblog/js/frontend/srilankaaddress/plugins/font-awesome-4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="/assets/addons/xcblog/js/frontend/srilankaaddress/plugins/owl.carousel.css">
    <link rel="stylesheet" type="text/css" href="/assets/addons/xcblog/js/frontend/srilankaaddress/plugins/owl.theme.default.css">
    <link rel="stylesheet" type="text/css" href="/assets/addons/xcblog/js/frontend/srilankaaddress/plugins/animate.css">
    <link rel="stylesheet" type="text/css" href="/assets/addons/xcblog/css/srilankaaddress/about.css">
    <link rel="stylesheet" type="text/css" href="/assets/addons/xcblog/css/srilankaaddress/about_responsive.css">
</head>

<body>
    <div class="super_container">
                <!-- Header -->
        <header class="header">
            <div class="container">
                <div class="row">
                    <div class="col">
                        <div class="header_content d-flex flex-row align-items-center justify-content-start">
                            <div class="logo">Sri Lanka<span> Address</span></div>
                            <nav class="main_nav">
                                <ul class="d-flex flex-row align-items-center justify-content-start">
                                                                        <li><a href="/">首页</a></li>
                                                                        <li><a href="/html/category/">文章分类</a></li>
                                                                        <li><a href="#">关于</a></li>
                                    <li><a href="#">联系</a></li>
                                </ul>
                            </nav>
                            <div class="social header_social">
                                <ul class="d-flex flex-row align-items-center justify-content-start">
                                    <li><a href="#"><i class="fa fa-pinterest" aria-hidden="true"></i></a></li>
                                    <li><a href="#"><i class="fa fa-linkedin" aria-hidden="true"></i></a></li>
                                    <li><a href="#"><i class="fa fa-instagram" aria-hidden="true"></i></a></li>
                                    <li><a href="#"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
                                    <li><a href="#"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
                                </ul>
                            </div>
                            <div class="hamburger ml-auto"><i class="fa fa-bars" aria-hidden="true"></i></div>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- Menu -->
        <div class="menu">
            <div class="menu_content d-flex flex-column align-items-center justify-content-center">
                <ul class="menu_nav_list text-center">
                                        <li><a href="index.html">Home</a></li>
                                        <li><a href="index.html">Home</a></li>
                                        <li><a href="#">关于</a></li>
                    <li><a href="#">联系</a></li>
                </ul>
            </div>
        </div>
        <!-- Home -->
        <div class="home">
            <div class="parallax_background parallax-window" data-parallax="scroll" data-image-src="/assets/addons/xcblog/img/srilankaaddress/about.jpg" data-speed="0.8"></div>
            <div class="home_container">
                <div class="container">
                    <div class="row">
                        <div class="col">
                            <div class="home_content">
                                <div class="home_title">深度学习训练过程中的学习率衰减策略及pytorch实现</div>
                                <div class="breadcrumbs">
                                    <ul class="d-flex flex-row align-items-center justify-content-start">
                                        <li><a href="/">首页</a></li>
                                        <li><a href="/html/category/">文章分类</a></li>
                                        <li>正文</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Classes -->
        <div class="classes">
            <div class="container">
                <div class="row">
                    <div class="col-md-9">
                        <div class="row row-eq-height">
                            <div class="col-md-12">
                                  				  				  				<p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">学习率是深度学习中的一个重要超参数，选择合适的学习率能够帮助模型更好地收敛。</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">本文主要介绍深度学习训练过程中的14种学习率衰减策略以及相应的Pytorch实现。</span></p> <h3 style="text-align: left; margin-left: 30px">1. StepLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">按固定的训练epoch数进行学习率衰减。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">举例说明：</span></li> </ul> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># lr = 0.05 if epoch &lt; 30</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># lr = 0.005 if 30 &lt;= epoch &lt; 60</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># lr = 0.0005 if 60 &lt;= epoch &lt; 90</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">在上述例子中，每30个epochs衰减十倍学习率。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">计算公式和pytorch计算代码如下：</span></li> </ul> <p style="margin-left: 30px"><img decoding="async" src="http://img.555519.xyz/uploads3/20220510/b8bd32e5e1a133a8109040b26c6cb9fd.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> _get_closed_form_lr(self):</span><span style="color: rgba(0, 0, 255, 1)">return</span> [base_lr * self.gamma ** (self.last_epoch //<span style="color: rgba(0, 0, 0, 1)"> self.step_size)</span><span style="color: rgba(0, 0, 255, 1)">for</span> base_lr<span style="color: rgba(0, 0, 255, 1)">in</span> self.base_lrs]</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=- 1, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">optimizer：表示使用的优化器；</span><br /><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">step_size：表示学习率调整步长；</span><br /><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">gamma：表示学习率衰减乘法因子，默认：0.1；</span><br /><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">last_epoch:表示上一个epoch数，默认：-1，此时学习率的值为初始学习率；</span><br /><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">verbose:表示是否每次更新都输出一次学习率的值，默认：False。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">代码示例及结果展示：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.1,last_epoch=-1)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">设置10个epoch时，输出训练过程中的学习率如下：</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><img fetchpriority="high" decoding="async" src="http://img.555519.xyz/uploads3/20220510/195a75c51a9a93473754861e51ec8535.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></span></p> <p style="margin-left: 30px"> <h3 style="margin-left: 30px">2. MultiStepLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">当epoch数达到固定数值进行学习率衰减。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">举例说明：</span></li> </ul> <p style="margin-left: 30px"><span class="n" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># milestones<span class="o">=<span class="p">[<span class="mi">30<span class="p">,<span class="mi">80<span class="p">]</span></span></span></span></span></span></span></p> <p style="margin-left: 30px"><span class="c1" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># lr = 0.05 if epoch &lt; 30</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="c1"><span class="gp"><span class="c1"># lr = 0.005 if 30 &lt;= epoch &lt; 80</span></span></span></span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="c1"><span class="gp"><span class="c1"><span class="gp"><span class="c1"># lr = 0.0005 if epoch &gt;= 80</span></span></span></span></span></span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">在上述例子中，当epoch达到milestones中的数值时进行学习率衰减。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">计算公式和pytorch计算代码如下：</span></li> </ul> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><img decoding="async" src="http://img.555519.xyz/uploads3/20220510/62ec7ab34fc5be81960fa9afb3d0ba9a.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">其中bisect_right函数表示epoch数插入milestones中列表的位置，</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">例如:milstones=[2,5,8]</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">last_epoch==1→bisect_right(milestones,last_epoch)=0;</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">last_epoch==3→bisect_right(milestones,last_epoch)=1;</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">last_epoch==6→bisect_right(milestones,last_epoch)=2;</span></p> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> _get_closed_form_lr(self):         milestones</span>=<span style="color: rgba(0, 0, 0, 1)"> list(sorted(self.milestones.elements()))</span><span style="color: rgba(0, 0, 255, 1)">return</span> [base_lr * self.gamma **<span style="color: rgba(0, 0, 0, 1)"> bisect_right(milestones, self.last_epoch)</span><span style="color: rgba(0, 0, 255, 1)">for</span> base_lr<span style="color: rgba(0, 0, 255, 1)">in</span> self.base_lrs]</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=- 1, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">milestones：一个关于epoch索引的列表，当epoch值达到列表中的数值时进行学习率衰减。</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">其他参数相同。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">代码示例及结果展示：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">lr_scheduler=torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[2,5,8],gamma=0.1,last_epoch=-1)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/9ab4d72166656f489250d324460ec2f0.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></span></p> <h3 style="margin-left: 30px">3. ExponentialLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">根据当前epoch进行学习率衰减</span></li> </ul> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">计算公式和pytorch计算代码如下：</span></li> </ul> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/af8ef19c5b6e553aef51d75e5ef55129.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> _get_closed_form_lr(self):</span><span style="color: rgba(0, 0, 255, 1)">return</span> [base_lr * self.gamma **<span style="color: rgba(0, 0, 0, 1)"> self.last_epoch</span><span style="color: rgba(0, 0, 255, 1)">for</span> base_lr<span style="color: rgba(0, 0, 255, 1)">in</span> self.base_lrs]</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=- 1, verbose=False)</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">代码示例及结果展示：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">lr_scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.1,last_epoch=-1)</span></pre> </div> <h3 style="margin-left: 30px"><em><em><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><img loading="lazy" decoding="async" src="https://img2022.cnblogs.com/blog/2801907/202203/2801907-20220327205632264-707263736.png" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"><br /></span></em><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><br /></span></em>4. linearLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">在epoch数达到total_iters数值之前，使用线性改变乘法因子衰减学习率。</span></li> </ul> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">计算公式和pytorch计算代码如下：</span></li> </ul> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/0e5dce092c753832efd541280ebbd318.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> _get_closed_form_lr(self):</span><span style="color: rgba(0, 0, 255, 1)">return</span> [base_lr * (self.start_factor +<span style="color: rgba(0, 0, 0, 1)">                 (self.end_factor</span>- self.start_factor) * min(self.total_iters, self.last_epoch) /<span style="color: rgba(0, 0, 0, 1)"> self.total_iters)</span><span style="color: rgba(0, 0, 255, 1)">for</span> base_lr<span style="color: rgba(0, 0, 255, 1)">in</span> self.base_lrs]</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.3333333333333333, end_factor=1.0, total_iters=5, last_epoch=- 1, verbose=False)</span></pre> </div> <pre><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">start_factor: 在第一个epoch中乘以base_lr的数值，默认1/3；<br/>end_factor:在线性变化过程结束时乘以base_lr的数值，默认：1；<br/>total_iters:乘法因子达到1的迭代次数，默认：5。<br/></span></pre> <ul> <li>举例说明：</li> </ul> <pre><span class="n" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">lr_scheduler<span class="o">=<span class="n">LinearLR<span class="p">(optimizer<span class="bp"><span class="o"><span class="n"><span class="p">,<span class="n">start_factor<span class="o">=<span class="mf">0.5<span class="p">,<span class="n">total_iters<span class="o">=<span class="mi">4<span class="p">)<br/>base_lr=0.05<br/># epoch == 0→lr = base_lr * start_factor = 0.05 * 0.5=0.025;<br/># epoch == 1→lr = 0.05 * (0.5 + 0.5 * 0.25) = 0.3125;<br/>......<br/># epoch ≥ 4→lr = base_lr * end_factor = 0.05(当epoch数等于total_iters时，</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">min(self.total_iters, self.last_epoch) / self.total_iters = 1)<br/></span></pre> <h3 style="margin-left: 30px">5. ConstantLR<span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><br /></span></h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">在epoch数达到total_iters数值之前，使用常数因子衰减学习率。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">计算公式和pytorch计算代码如下：</span></li> </ul> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/60e443b667eba1262fe6a14f3aea250b.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> _get_closed_form_lr(self):</span><span style="color: rgba(0, 0, 255, 1)">return</span> [base_lr * (self.factor + (self.last_epoch &gt;= self.total_iters) * (1 -<span style="color: rgba(0, 0, 0, 1)"> self.factor))</span><span style="color: rgba(0, 0, 255, 1)">for</span> base_lr<span style="color: rgba(0, 0, 255, 1)">in</span> self.base_lrs]</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.ConstantLR(optimizer, factor=0.3333333333333333, total_iters=5, last_epoch=- 1, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">&nbsp;factor：在epoch达到total_iters之前，学习率乘以的常数因子，默认1/3；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">&nbsp;total_iters:衰减学习率的步数。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">举例说明：</span></li> </ul> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">lr_scheduler = ConstantLR(self.opt, factor=0.5, total_iters=4)</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">base_lr = 0.05</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># epoch == 0&nbsp;→ lr = base_lr * (factor + 0 * (1-factor)) = 0.05 *&nbsp; 0.5 = 0.025</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">......</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># epoch == 4&nbsp;→ lr = base_lr * (factor + 1 - factor) = 0.05</span></p> <h3 style="margin-left: 30px">6. LambdaLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">使用lambda定义的函数衰减学习率。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">计算公式和pytorch计算代码如下：</span></li> </ul> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/2bfc69b7f43435ee83352461ec057180.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> get_lr(self):</span><span style="color: rgba(0, 0, 255, 1)">if</span><span style="color: rgba(0, 0, 255, 1)">not</span><span style="color: rgba(0, 0, 0, 1)"> self._get_lr_called_within_step:             warnings.warn(</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">To get the last learning rate computed by the scheduler,</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">please use `get_last_lr()`.</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)</span><span style="color: rgba(0, 0, 255, 1)">return</span> [base_lr *<span style="color: rgba(0, 0, 0, 1)"> lmbda(self.last_epoch)</span><span style="color: rgba(0, 0, 255, 1)">for</span> lmbda, base_lr<span style="color: rgba(0, 0, 255, 1)">in</span> zip(self.lr_lambdas, self.base_lrs)]</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=- 1, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">lr_lambda:当给定epoch数，计算乘法因子的函数（可以自己定义）</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">代码示例及结果展示：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">lr_scheduler=torch.optim.lr_scheduler.LambdaLR(optimizer,lr_lambda=<span style="color: rgba(0, 0, 255, 1)">lambda</span> epoch:epoch/30 )</span></pre> </div> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/ccba4daa059db058452904c027ac2ba3.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <p style="margin-left: 30px"> <h3 style="margin-left: 30px">7. MultiplicativeLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">同样是使用了与epoch有关的lambda函数，与LambdaLR不同的地方在于，它是对old_lr更新。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">计算公式和pytorch计算代码如下：</span></li> </ul> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/41d7399c645bcb0bb307361a61a32be4.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> get_lr(self):</span><span style="color: rgba(0, 0, 255, 1)">if</span><span style="color: rgba(0, 0, 255, 1)">not</span><span style="color: rgba(0, 0, 0, 1)"> self._get_lr_called_within_step:             warnings.warn(</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">To get the last learning rate computed by the scheduler,</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">please use `get_last_lr()`.</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, UserWarning)</span><span style="color: rgba(0, 0, 255, 1)">if</span> self.last_epoch &gt;<span style="color: rgba(0, 0, 0, 1)"> 0:</span><span style="color: rgba(0, 0, 255, 1)">return</span> [group[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">lr</span><span style="color: rgba(128, 0, 0, 1)">'</span>] *<span style="color: rgba(0, 0, 0, 1)"> lmbda(self.last_epoch)</span><span style="color: rgba(0, 0, 255, 1)">for</span> lmbda, group<span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> zip(self.lr_lambdas, self.optimizer.param_groups)]</span><span style="color: rgba(0, 0, 255, 1)">else</span><span style="color: rgba(0, 0, 0, 1)">:</span><span style="color: rgba(0, 0, 255, 1)">return</span> [group[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">lr</span><span style="color: rgba(128, 0, 0, 1)">'</span>]<span style="color: rgba(0, 0, 255, 1)">for</span> group<span style="color: rgba(0, 0, 255, 1)">in</span> self.optimizer.param_groups]</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="font-family: &quot;times new roman&quot;, times">torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda, last_epoch=- 1, verbose=False)</span></span></pre> </div> <p style="margin-left: 30px"> <h3 style="margin-left: 30px">8. CosineAnnealingLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">模拟余弦退火曲线调整学习率</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">计算公式和pytorch计算代码如下：</span></li> </ul> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/917f7c5f409592a8848114d31c359319.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> _get_closed_form_lr(self):</span><span style="color: rgba(0, 0, 255, 1)">return</span> [self.eta_min + (base_lr - self.eta_min) *<span style="color: rgba(0, 0, 0, 1)">            (</span>1 + math.cos(math.pi * self.last_epoch / self.T_max)) / 2<span style="color: rgba(0, 0, 255, 1)">for</span> base_lr<span style="color: rgba(0, 0, 255, 1)">in</span> self.base_lrs]</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=- 1, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">T_max:最大迭代次数，一次学习率周期的迭代次数。</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">eta_min:最小学习率，默认：0。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">代码示例及结果展示：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">lr_scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=3,eta_min=0)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">base_lr=0.01</span></p> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/e1902cb442cdfbf44dfa36eb21573bff.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">当epoch是T_max的奇数倍时，学习率会下降到最小值eta_min。</span></p> <p style="margin-left: 30px"> <h3 style="margin-left: 30px">9. ChainedScheduler</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">可以调用其他学习率调整策略。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.ChainedScheduler(schedulers)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">schedules:设置的其他学习率调整策略，可以是一个包含多个学习率调整策略的列表</span>。</p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">代码示例及结果：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">scheduler1 = ConstantLR(self.opt, factor=0.1, total_iters=2<span style="color: rgba(0, 0, 0, 1)">)</span>scheduler2 = ExponentialLR(self.opt, gamma=0.9<span style="color: rgba(0, 0, 0, 1)">)</span>lr_scheduler = ChainedScheduler([scheduler1, scheduler2])</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">schedules里的学习率调整策略同时使用</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">base_lr = 1</span></p> <p style="margin-left: 30px"><span class="c1" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># lr = 0.09 if epoch == 0 （先使用scheduler2策略得到lr = 0.9;再使用scheduler1策略得到最终new_lr = 0.09)</span></p> <p style="margin-left: 30px"><span class="c1" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="gp"><span class="c1"># lr = 0.081 if epoch == 1</span></span></span></p> <p style="margin-left: 30px"><span class="c1" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="gp"><span class="c1"><span class="gp"><span class="c1"># lr = 0.729 if epoch == 2</span></span></span></span></span></p> <p style="margin-left: 30px"><span class="c1" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="gp"><span class="c1"><span class="gp"><span class="c1"><span class="gp"><span class="c1"># lr = 0.6561 if epoch == 3</span></span></span></span></span></span></span></p> <p style="margin-left: 30px"><span class="c1" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="gp"><span class="c1"><span class="gp"><span class="c1"><span class="gp"><span class="c1"><span class="gp"><span class="c1"># lr = 0.59049 if epoch &gt;= 4</span></span></span></span></span></span></span></span></span></p> <h3 style="margin-left: 30px">10.SequentialLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">与ChainedScheduler在每一个epoch中同时调用schedules中的学习率策略不同的是，SequentialLR针对epoch按顺序调用schedules中的学习率策略。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers, milestones, last_epoch=- 1, verbose=False)</span></pre> </div> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">代码示例及结果：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">scheduler1 = ConstantLR(self.opt, factor=0.1, total_iters=2<span style="color: rgba(0, 0, 0, 1)">)</span>scheduler2 = ExponentialLR(self.opt, gamma=0.9<span style="color: rgba(0, 0, 0, 1)">)</span>lr_scheduler = SequentialLR(optimizer, schedulers=[scheduler1, scheduler2], milestones=[2])</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">base_lr = 1</span></p> <p style="margin-left: 30px"><span class="sd" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"># lr = 0.1 if epoch == 0</span></p> <p style="margin-left: 30px"><span class="sd" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="sd"># lr = 0.1 if epoch == 1</span></span></p> <p style="margin-left: 30px"><span class="sd" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="sd"><span class="sd"># lr = 0.9 if epoch == 2</span></span></span></p> <p style="margin-left: 30px"><span class="sd" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="sd"><span class="sd"><span class="sd"># lr = 0.81 if epoch == 3</span></span></span></span></p> <p style="margin-left: 30px"><span class="sd" style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px"><span class="sd"><span class="sd"><span class="sd"><span class="sd"># lr = 0.729 if epoch == 4</span></span></span></span></span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">epoch&lt;milestones,调用scheduler1学习率调整策略，epoch≥milestones，调用scheduler2学习率调整策略。</span></p> <p style="margin-left: 30px"> <h3 style="margin-left: 30px">11.ReduceLROnPlateau</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">当训练指标不再改进时，调整学习率。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">min</span><span style="color: rgba(128, 0, 0, 1)">'</span>, factor=0.1, patience=10, threshold=0.0001, threshold_mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">rel</span><span style="color: rgba(128, 0, 0, 1)">'</span>, cooldown=0, min_lr=0, eps=1e-08, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">mode:有min、max两种模式，在 min 模式下，当指标的数量停止减少时（如loss），学习率将减少； 在max模式下，当指标的数量停止增加时（如accuracy），学习率将减少，默认值：min；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">factor:学习率减少的倍数，new_lr = old_lr * factor,默认：0.1；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">patience:指标没有提升的epoch数，之后降低学习率。例如，patience = 2，会忽略前 2 个没有改善的 epoch，并且只有在第 3 个 epoch 之后指标仍然没有改善的情况下降低 学习率。 默认值：10。</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">threshold:衡量新的最佳阈值，只关注重大变化。 默认值：1e-4。</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">threshold_mode:有rel、abs两种模式，</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">cooldown:在 学习率减少后恢复正常操作之前要等待的 epoch 数。 默认值：0。</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">min_lr:标量或标量列表。学习率的下限。 默认值：0。</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">eps:应用于 学习率的最小衰减。 如果新旧 学习率之间的差异小于 eps，则忽略更新。 默认值：1e-8。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">代码示例及结果：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">lr_scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=2,cooldown=2)</span></pre> </div> <p style="margin-left: 30px"><img loading="lazy" decoding="async" src="http://img.555519.xyz/uploads3/20220510/386b2d949836f14b95aace56748fe681.jpg" alt="深度学习训练过程中的学习率衰减策略及pytorch实现"></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">第一个epoch是初始学习率；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">设置patience = 2，即指标在经历3个epoch后仍然没有提升，衰减学习率，new_lr = old_lr * factor(0.1)，如图中第4个epoch时开始衰减学习率；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">设置cooldown = 2，即衰减学习率后有2个epoch的cooldown时期（5、6epoch），在cooldown时期不进行patience阶段的epoch计数；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">cooldown时期结束恢复patience阶段epoch计数（图中从第7个epoch开始计数，在第10个epoch学习率衰减）。</span></p> <h3 style="margin-left: 30px">12.CyclicLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">根据循环学习策略设置学习率。（每训练一个batch，更新一次学习率）</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">在《&nbsp;Cyclical Learning Rates for Training Neural Networks》这篇文章中有详细描述。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=2000, step_size_down=None, mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">triangular</span><span style="color: rgba(128, 0, 0, 1)">'</span>, gamma=1.0, scale_fn=None, scale_mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">cycle</span><span style="color: rgba(128, 0, 0, 1)">'</span>, cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=- 1, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">base_lr:初始学习率,循环中的学习率下边界；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">max_lr:每个参数组在循环中的上层学习率边界。从功能上讲，它定义了周期幅度 (max_lr - base_lr)。任何周期的 lr 是 base_lr 和一些幅度缩放的总和；因此 max_lr 实际上可能无法达到，具体取决于缩放函数。</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">step_size_up:在一个周期增加的一半中训练迭代的次数。默认值：2000；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">step_size_down:循环减半中的训练迭代次数。如果 step_size_down 为 None，则设置为 step_size_up。默认值：None；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">mode:包含三种{triangular, triangular2, exp_range} ，如果 scale_fn 不是 None，则忽略此参数。默认值：“triangular”；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">gamma:‘exp_range’ 缩放函数中的常数：gamma**（cycle iterations）默认值：1.0；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">scale_fn:由单个参数 lambda 函数定义的自定义缩放策略，其中 0 &lt;= scale_fn(x) &lt;= 1 for all x &gt;= 0。如果指定，则忽略“mode”。默认值：None；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">scale_mode:{‘cycle’, ‘iterations’}。定义是否在cycle number或<span class="sd">cycle iterations (training<span class="sd"> iterations since start of cycle)</span></span>上评估 scale_fn。默认值：cycle；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">cycle_momentum:如果为真，则动量与“base_momentum”和“max_momentum”之间的学习率成反比。默认值：True；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">base_momentum: 循环中的动量下边界，默认值：0.8；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">max_monmentum:循环中的动量上边界，默认值：0.9；</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">官方代码及示例：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9<span style="color: rgba(0, 0, 0, 1)">)</span>scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1<span style="color: rgba(0, 0, 0, 1)">)</span>data_loader =<span style="color: rgba(0, 0, 0, 1)"> torch.utils.data.DataLoader(...)</span><span style="color: rgba(0, 0, 255, 1)">for</span> epoch<span style="color: rgba(0, 0, 255, 1)">in</span> range(10<span style="color: rgba(0, 0, 0, 1)">):</span><span style="color: rgba(0, 0, 255, 1)">for</span> batch<span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> data_loader:</span><span style="color: rgba(0, 0, 0, 1)">         train_batch(...)</span>         scheduler.step()</span></pre> </div> <h3 style="margin-left: 30px">13.OneCycleLR</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">根据循环学习策略设置学习率。（每训练一个batch，更新一次学习率）</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">相关文章《Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates》</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, total_steps=None, epochs=None, steps_per_epoch=None, pct_start=0.3, anneal_strategy=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">cos</span><span style="color: rgba(128, 0, 0, 1)">'</span>, cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0, three_phase=False, last_epoch=- 1, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">max_lr:在循环中的上层学习率边界；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">total_steps:循环总步数。如果此处未提供值，则必须通过提供 epochs 和 steps_per_epoch 的值来推断。默认值：None；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">epochs:训练的epochs；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">steps_per_epoch:每个 epoch 训练的步数；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pct_start:提高学习率所花费的周期百分比（in number of steps）。默认值：0.3；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">anneal_strategy:{‘cos’, ‘linear’} 指定退火策略：“cos”表示余弦退火，“linear”表示线性退火。默认值：'cos'；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">div_factor:通过 initial_lr = max_lr/div_factor 确定初始学习率 默认值：25;</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">final_div_factor:通过 min_lr = initial_lr/final_div_factor 确定最小学习率 默认值：1e4;</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">three_phase:如果为 True，则使用计划的第三阶段根据“final_div_factor”消除学习率，而不是修改第二阶段（前两个阶段将关于“pct_start”指示的步骤对称）。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">官方代码及示例：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"> data_loader =<span style="color: rgba(0, 0, 0, 1)"> torch.utils.data.DataLoader(...)      optimizer</span>= torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9<span style="color: rgba(0, 0, 0, 1)">)      scheduler</span>= torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(data_loader), epochs=10<span style="color: rgba(0, 0, 0, 1)">)</span><span style="color: rgba(0, 0, 255, 1)">for</span> epoch<span style="color: rgba(0, 0, 255, 1)">in</span> range(10<span style="color: rgba(0, 0, 0, 1)">):</span><span style="color: rgba(0, 0, 255, 1)">for</span> batch<span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> data_loader:             train_batch(...)             scheduler.step()</span></span></pre> </div> <h3 style="margin-left: 30px"></h3> <h3 style="margin-left: 30px">14.CosineAnnealingWarmRestarts</h3> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">和余弦退火类似，多了warmrestart操作。</span></li> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">pytorch调用及相关参数：</span></li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px">torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0, T_mult=1, eta_min=0, last_epoch=- 1, verbose=False)</span></pre> </div> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">T_0:第一次restart的迭代次数；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">T_mult:在一次restar后，因子增加：math:`T_{i}；</span></p> <p style="margin-left: 30px"><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">eta_min:最小学习率，默认值：0。</span></p> <ul> <li><span style="font-family: 楷体, &quot;Kaiti SC&quot;; font-size: 18px">官方代码及示例</span>：</li> </ul> <div class="cnblogs_code"> <pre><span style="font-family: &quot;times new roman&quot;, times; font-size: 15px"> scheduler =<span style="color: rgba(0, 0, 0, 1)"> CosineAnnealingWarmRestarts(optimizer, T_0, T_mult)                  iters</span>=<span style="color: rgba(0, 0, 0, 1)"> len(dataloader)</span><span style="color: rgba(0, 0, 255, 1)">for</span> epoch<span style="color: rgba(0, 0, 255, 1)">in</span> range(20<span style="color: rgba(0, 0, 0, 1)">):</span><span style="color: rgba(0, 0, 255, 1)">for</span> i, sample<span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> enumerate(dataloader):                          inputs, labels</span>= sample[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">inputs</span><span style="color: rgba(128, 0, 0, 1)">'</span>], sample[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">labels</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">]                          optimizer.zero_grad()                          outputs</span>=<span style="color: rgba(0, 0, 0, 1)"> net(inputs)                          loss</span>=<span style="color: rgba(0, 0, 0, 1)"> criterion(outputs, labels)                          loss.backward()                          optimizer.step()                          scheduler.step(epoch</span>+ i / iters)</span></pre> </div> <p>参考及引用：</p> <p>1.https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate</p> <p>2.https://zhuanlan.zhihu.com/p/352744991</p> <p>3.https://blog.csdn.net/qyhaill/article/details/103043637</p> 			
                                <div class="col-md-12 mt-5">
                                                                        <p>上一个：<a href="/html/category/article-1536.htm">Elasticsearch -from + size设置</a></p>
                                                                        <p>下一个：<a href="/html/category/article-1538.htm">从Paxos到ZooKeeper-一致性协议之2PC、3PC</a></p>
                                                                    </div>

                                                            </div>
                        </div>
                    </div>
                    <div class="col-md-3">
                        <div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">热门文章</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2"><a href="/html/category/article-1590.htm" title="Python  turtle  模块可以编写游戏，是真的吗？">Python  turtle  模块可以编写游戏，是真的吗？</a></li>
                        <li class="py-2"><a href="/html/category/article-2539.htm" title="Vue如何使用Element-ui表单发送数据与多张图片到后端详解_vue.js">Vue如何使用Element-ui表单发送数据与多张图片到后端详解_vue.js</a></li>
                        <li class="py-2"><a href="/html/category/article-1613.htm" title="vue 动态组件组件复用_真正的动态声明性组件">vue 动态组件组件复用_真正的动态声明性组件</a></li>
                        <li class="py-2"><a href="/html/category/article-1609.htm" title="聚类算法——python实现层次聚类（AGNES）">聚类算法——python实现层次聚类（AGNES）</a></li>
                        <li class="py-2"><a href="/html/category/article-1627.htm" title="go语言编译过程概述">go语言编译过程概述</a></li>
                        <li class="py-2"><a href="/html/category/article-1586.htm" title="tensorflow基础流程">tensorflow基础流程</a></li>
                        <li class="py-2"><a href="/html/category/article-1592.htm" title="SpringBoot时区问题解决，彻底解决时差问题">SpringBoot时区问题解决，彻底解决时差问题</a></li>
                        <li class="py-2"><a href="/html/category/article-1623.htm" title="Java集合类型遍历和排序">Java集合类型遍历和排序</a></li>
                        <li class="py-2"><a href="/html/category/article-2249.htm" title=".NET Core Hangfire任务计划_在线工具">.NET Core Hangfire任务计划_在线工具</a></li>
                        <li class="py-2"><a href="/html/category/article-1589.htm" title="浅谈Vue的双向绑定和单向数据流冲突吗_vue.js_">浅谈Vue的双向绑定和单向数据流冲突吗_vue.js_</a></li>
                    </ul>
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">归纳</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">48</span> <a href="/html/date/2024-06/" title="2024-06 归档">2024-06</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-05/" title="2024-05 归档">2024-05</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">60</span> <a href="/html/date/2024-04/" title="2024-04 归档">2024-04</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-03/" title="2024-03 归档">2024-03</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">50</span> <a href="/html/date/2024-02/" title="2024-02 归档">2024-02</a></h4>
            </li>
                    </ul>
    </div>
</div>

                    </div>
                </div>
            </div>
        </div>
                <!-- Footer -->
        <footer class="footer">
            <div class="parallax_background parallax-window" data-parallax="scroll" data-image-src="/assets/addons/xcblog/img/srilankaaddress/footer.jpg" data-speed="0.8"></div>
            <div class="footer_overlay"></div>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <div class="footer_content text-center d-flex flex-column align-items-center justify-content-center">
                            <p>
                                Sri Lanka Address 版权所有
                                <br />
                                Powered by WordPress
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </footer>
    </div>
    <script src="/assets/addons/xcblog/js/frontend/srilankaaddress/jquery-3.2.1.min.js"></script>
    <script src="/assets/addons/xcblog/css/srilankaaddress/bootstrap-4.1.2/popper.js"></script>
    <script src="/assets/addons/xcblog/css/srilankaaddress/bootstrap-4.1.2/bootstrap.min.js"></script>
    <script src="/assets/addons/xcblog/js/frontend/srilankaaddress/plugins/owl.carousel.js"></script>
    <script src="/assets/addons/xcblog/js/frontend/srilankaaddress/plugins/easing/easing.js"></script>
    <script src="/assets/addons/xcblog/js/frontend/srilankaaddress/plugins/parallax-js-master/parallax.min.js"></script>
    <script src="/assets/addons/xcblog/js/frontend/srilankaaddress/about.js"></script>
    <script>
    $(function() {
        $('.js_to').click(function(){
            var url = $(this).data('url');
            var code = $(this).data('code');
            url += code;

            window.open(url);
        })
    });
    </script>
</body>

</html>